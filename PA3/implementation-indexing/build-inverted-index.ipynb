{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d347c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('inverted-index.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a00ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''\n",
    "    CREATE TABLE IndexWord (\n",
    "        word TEXT PRIMARY KEY\n",
    "    );\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "    CREATE TABLE Posting (\n",
    "        word TEXT NOT NULL,\n",
    "        documentName TEXT NOT NULL,\n",
    "        frequency INTEGER NOT NULL,\n",
    "        indexes TEXT NOT NULL,\n",
    "        PRIMARY KEY(word, documentName),\n",
    "        FOREIGN KEY (word) REFERENCES IndexWord(word)\n",
    "    );\n",
    "''')\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49883eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words_slovene = set(stopwords.words(\"slovene\")).union(set(\n",
    "        [\"ter\",\"nov\",\"novo\", \"nova\",\"zato\",\"še\", \"zaradi\", \"a\", \"ali\", \"april\", \"avgust\", \"b\", \"bi\", \"bil\", \"bila\", \"bile\", \"bili\", \"bilo\", \"biti\",\n",
    "         \"blizu\", \"bo\", \"bodo\", \"bojo\", \"bolj\", \"bom\", \"bomo\", \"boste\", \"bova\", \"boš\", \"brez\", \"c\", \"cel\", \"cela\",\n",
    "         \"celi\", \"celo\", \"d\", \"da\", \"daleč\", \"dan\", \"danes\", \"datum\", \"december\", \"deset\", \"deseta\", \"deseti\", \"deseto\",\n",
    "         \"devet\", \"deveta\", \"deveti\", \"deveto\", \"do\", \"dober\", \"dobra\", \"dobri\", \"dobro\", \"dokler\", \"dol\", \"dolg\",\n",
    "         \"dolga\", \"dolgi\", \"dovolj\", \"drug\", \"druga\", \"drugi\", \"drugo\", \"dva\", \"dve\", \"e\", \"eden\", \"en\", \"ena\", \"ene\",\n",
    "         \"eni\", \"enkrat\", \"eno\", \"etc.\", \"f\", \"februar\", \"g\", \"g.\", \"ga\", \"ga.\", \"gor\", \"gospa\", \"gospod\", \"h\", \"halo\",\n",
    "         \"i\", \"idr.\", \"ii\", \"iii\", \"in\", \"iv\", \"ix\", \"iz\", \"j\", \"januar\", \"jaz\", \"je\", \"ji\", \"jih\", \"jim\", \"jo\",\n",
    "         \"julij\", \"junij\", \"jutri\", \"k\", \"kadarkoli\", \"kaj\", \"kajti\", \"kako\", \"kakor\", \"kamor\", \"kamorkoli\", \"kar\",\n",
    "         \"karkoli\", \"katerikoli\", \"kdaj\", \"kdo\", \"kdorkoli\", \"ker\", \"ki\", \"kje\", \"kjer\", \"kjerkoli\", \"ko\", \"koder\",\n",
    "         \"koderkoli\", \"koga\", \"komu\", \"kot\", \"kratek\", \"kratka\", \"kratke\", \"kratki\", \"l\", \"lahka\", \"lahke\", \"lahki\",\n",
    "         \"lahko\", \"le\", \"lep\", \"lepa\", \"lepe\", \"lepi\", \"lepo\", \"leto\", \"m\", \"maj\", \"majhen\", \"majhna\", \"majhni\",\n",
    "         \"malce\", \"malo\", \"manj\", \"marec\", \"me\", \"med\", \"medtem\", \"mene\", \"mesec\", \"mi\", \"midva\", \"midve\", \"mnogo\",\n",
    "         \"moj\", \"moja\", \"moje\", \"mora\", \"morajo\", \"moram\", \"moramo\", \"morate\", \"moraš\", \"morem\", \"mu\", \"n\", \"na\", \"nad\",\n",
    "         \"naj\", \"najina\", \"najino\", \"najmanj\", \"naju\", \"največ\", \"nam\", \"narobe\", \"nas\", \"nato\", \"nazaj\", \"naš\", \"naša\",\n",
    "         \"naše\", \"ne\", \"nedavno\", \"nedelja\", \"nek\", \"neka\", \"nekaj\", \"nekatere\", \"nekateri\", \"nekatero\", \"nekdo\",\n",
    "         \"neke\", \"nekega\", \"neki\", \"nekje\", \"neko\", \"nekoga\", \"nekoč\", \"ni\", \"nikamor\", \"nikdar\", \"nikjer\", \"nikoli\",\n",
    "         \"nič\", \"nje\", \"njega\", \"njegov\", \"njegova\", \"njegovo\", \"njej\", \"njemu\", \"njen\", \"njena\", \"njeno\", \"nji\",\n",
    "         \"njih\", \"njihov\", \"njihova\", \"njihovo\", \"njiju\", \"njim\", \"njo\", \"njun\", \"njuna\", \"njuno\", \"no\", \"nocoj\",\n",
    "         \"november\", \"npr.\", \"o\", \"ob\", \"oba\", \"obe\", \"oboje\", \"od\", \"odprt\", \"odprta\", \"odprti\", \"okoli\", \"oktober\",\n",
    "         \"on\", \"onadva\", \"one\", \"oni\", \"onidve\", \"osem\", \"osma\", \"osmi\", \"osmo\", \"oz.\", \"p\", \"pa\", \"pet\", \"peta\",\n",
    "         \"petek\", \"peti\", \"peto\", \"po\", \"pod\", \"pogosto\", \"poleg\", \"poln\", \"polna\", \"polni\", \"polno\", \"ponavadi\",\n",
    "         \"ponedeljek\", \"ponovno\", \"potem\", \"povsod\", \"pozdravljen\", \"pozdravljeni\", \"prav\", \"prava\", \"prave\", \"pravi\",\n",
    "         \"pravo\", \"prazen\", \"prazna\", \"prazno\", \"prbl.\", \"precej\", \"pred\", \"prej\", \"preko\", \"pri\", \"pribl.\",\n",
    "         \"približno\", \"primer\", \"pripravljen\", \"pripravljena\", \"pripravljeni\", \"proti\", \"prva\", \"prvi\", \"prvo\", \"r\",\n",
    "         \"ravno\", \"redko\", \"res\", \"reč\", \"s\", \"saj\", \"sam\", \"sama\", \"same\", \"sami\", \"samo\", \"se\", \"sebe\", \"sebi\",\n",
    "         \"sedaj\", \"sedem\", \"sedma\", \"sedmi\", \"sedmo\", \"sem\", \"september\", \"seveda\", \"si\", \"sicer\", \"skoraj\", \"skozi\",\n",
    "         \"slab\", \"smo\", \"so\", \"sobota\", \"spet\", \"sreda\", \"srednja\", \"srednji\", \"sta\", \"ste\", \"stran\", \"stvar\", \"sva\",\n",
    "         \"t\", \"ta\", \"tak\", \"taka\", \"take\", \"taki\", \"tako\", \"takoj\", \"tam\", \"te\", \"tebe\", \"tebi\", \"tega\", \"težak\",\n",
    "         \"težka\", \"težki\", \"težko\", \"ti\", \"tista\", \"tiste\", \"tisti\", \"tisto\", \"tj.\", \"tja\", \"to\", \"toda\", \"torek\",\n",
    "         \"tretja\", \"tretje\", \"tretji\", \"tri\", \"tu\", \"tudi\", \"tukaj\", \"tvoj\", \"tvoja\", \"tvoje\", \"u\", \"v\", \"vaju\", \"vam\",\n",
    "         \"vas\", \"vaš\", \"vaša\", \"vaše\", \"ve\", \"vedno\", \"velik\", \"velika\", \"veliki\", \"veliko\", \"vendar\", \"ves\", \"več\",\n",
    "         \"vi\", \"vidva\", \"vii\", \"viii\", \"visok\", \"visoka\", \"visoke\", \"visoki\", \"vsa\", \"vsaj\", \"vsak\", \"vsaka\", \"vsakdo\",\n",
    "         \"vsake\", \"vsaki\", \"vsakomur\", \"vse\", \"vsega\", \"vsi\", \"vso\", \"včasih\", \"včeraj\", \"x\", \"z\", \"za\", \"zadaj\",\n",
    "         \"zadnji\", \"zakaj\", \"zaprta\", \"zaprti\", \"zaprto\", \"zdaj\", \"zelo\", \"zunaj\", \"č\", \"če\", \"često\", \"četrta\",\n",
    "         \"četrtek\", \"četrti\", \"četrto\", \"čez\", \"čigav\", \"š\", \"šest\", \"šesta\", \"šesti\", \"šesto\", \"štiri\", \"ž\", \"že\",\n",
    "         \"svoj\", \"jesti\", \"imeti\",\"\\u0161e\", \"iti\", \"kak\", \"www\", \"km\", \"eur\", \"pač\", \"del\", \"kljub\", \"šele\", \"prek\",\n",
    "         \"preko\", \"znova\", \"morda\",\"kateri\",\"katero\",\"katera\", \"ampak\", \"lahek\", \"lahka\", \"lahko\", \"morati\", \"torej\",\n",
    "         \"(\", \")\", \"--\", \";\", \".\", \",\", \"/\", \"-\", \"!\", \"?\", \"'\", \":\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0889cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.util import string_span_tokenize\n",
    "import tokenizations\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('inverted-index.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "path_to_file = \"C:/Users/miham/Documents/Faks/IEPS/PA3/PA3-data/evem.gov.si/evem.gov.si.4.html\"\n",
    "root = \"C:/Users/miham/Documents/Faks/IEPS/PA3/PA3-data\"\n",
    "stop_words_english = stopwords.words('english')\n",
    "\n",
    "#tokenize, insert into database test\n",
    "\"\"\"\n",
    "with open(path_to_file, encoding=\"utf8\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "    \n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # remove script tags, style tags\n",
    "            \n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if not t in stop_words_slovene]\n",
    "    tokens = [t for t in tokens if not t in stop_words_english]\n",
    "    \n",
    "    spans = []\n",
    "    ix = 0\n",
    "    for token in tokens:\n",
    "        ix = text.find(token, ix)\n",
    "        spans.append(ix)\n",
    "        ix += len(token)\n",
    "    \n",
    "    #print(tokens)\n",
    "    #print(spans)\n",
    "\n",
    "    rev_ix = {}\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in rev_ix:\n",
    "            rev_ix[tokens[i]] = [1, [spans[i]]]\n",
    "        else:\n",
    "            rev_ix[tokens[i]][0] += 1\n",
    "            rev_ix[tokens[i]][1].append(spans[i])\n",
    "    \n",
    "    addr = 'evem.gov.si/evem.gov.si.4.html'\n",
    "    for key in rev_ix:\n",
    "        cur.execute('''SELECT word FROM IndexWord WHERE word =?''', (key,))\n",
    "        exists = cur.fetchall()\n",
    "        data = rev_ix[key]\n",
    "        f = data[0]\n",
    "        indices = ','.join(str(e) for e in data[1])\n",
    "        \n",
    "        if not exists:\n",
    "            cur.execute('''INSERT INTO IndexWord VALUES (?)''', (key,))\n",
    "            cur.execute('''INSERT INTO Posting VALUES (?,?,?,?)''',(key, addr, f, indices))\n",
    "        else:\n",
    "            cur.execute('''INSERT INTO Posting VALUES (?,?,?,?)''',(key, addr, f, indices))\n",
    "            \n",
    "        conn.commit()\n",
    "\"\"\"\n",
    "for subdir, dirs, files in os.walk(root):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        domain = os.path.basename(os.path.normpath(subdir))\n",
    "        site = file\n",
    "        addr = domain + '/' + site\n",
    " \n",
    "        with open(path, encoding='utf8') as fp:\n",
    "            soup = BeautifulSoup(fp, 'html.parser')\n",
    "    \n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()    # remove script tags, style tags\n",
    "\n",
    "            # get text, tokenize text, and remove stop words\n",
    "            text = soup.get_text()\n",
    "            text = text.lower()\n",
    "            tokens = word_tokenize(text)\n",
    "            tokens = [t for t in tokens if not t in stop_words_slovene]\n",
    "            tokens = [t for t in tokens if not t in stop_words_english]\n",
    "            \n",
    "            # find spans of tokens in original text \n",
    "            spans = []\n",
    "            ix = 0\n",
    "            for token in tokens:\n",
    "                ix = text.find(token, ix)\n",
    "                spans.append(ix)\n",
    "                ix += len(token)\n",
    "            \n",
    "            # build local reverse index for given document\n",
    "            rev_ix = {}\n",
    "            for i in range(len(tokens)):\n",
    "                if tokens[i] not in rev_ix:\n",
    "                    rev_ix[tokens[i]] = [1, [spans[i]]]\n",
    "                else:\n",
    "                    rev_ix[tokens[i]][0] += 1\n",
    "                    rev_ix[tokens[i]][1].append(spans[i])\n",
    "            \n",
    "            # write value to database\n",
    "            for key in rev_ix:\n",
    "                cur.execute('''SELECT word FROM IndexWord WHERE word =?''', (key,))\n",
    "                exists = cur.fetchall()\n",
    "                data = rev_ix[key]\n",
    "                f = data[0]\n",
    "                indices = ','.join(str(e) for e in data[1])\n",
    "                \n",
    "                # check if token exists in IndexWords\n",
    "                if not exists:\n",
    "                    cur.execute('''INSERT INTO IndexWord VALUES (?)''', (key,)) \n",
    "                    cur.execute('''INSERT INTO Posting VALUES (?,?,?,?)''',(key, addr, f, indices))\n",
    "                else:\n",
    "                    cur.execute('''INSERT INTO Posting VALUES (?,?,?,?)''',(key, addr, f, indices))\n",
    "\n",
    "                conn.commit()\n",
    "\n",
    "print(\"DONE!\")\n",
    "         \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
